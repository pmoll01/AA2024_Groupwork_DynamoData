{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Jupyter Notebook for Task 4: Modeling\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preperation\n",
    "Before we start modeling, we have to load the packages and the data, and prepare it so it can be processed by the models."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Polynomial regression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Neural network\n",
    "from keras import Sequential  # Sequential model: https://keras.io/guides/sequential_model/\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Import custom functions and utilities\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "\n",
    "# Time series analysis\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.seasonal import MSTL\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Environment settings\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# Matplotlib settings\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "agg_charging_data = pd.read_pickle(os.path.join('Data', 'aggregated_data.pkl'))\n",
    "agg_charging_data['year'] = agg_charging_data.index.year\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(agg_charging_data.index, agg_charging_data['utilizationRate_total'], label='Utilization Total', color='blue')\n",
    "plt.legend()\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(agg_charging_data.index, agg_charging_data['utilizationRate_site1'], label='Utilization Site1', color='red')\n",
    "plt.legend()\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(agg_charging_data.index, agg_charging_data['utilizationRate_site2'], label='Utilization Site2', color='orange')\n",
    "plt.legend()\n",
    "\n",
    "agg_charging_data.info(20)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If we plot the utilization over time, we can observe some interesting pattern. The Strong dip at around 03/2020 can be explained with the corona pandamic. Besides there is a time frame with no values. The objective for this task (based on the Data mining goal) is to predict the untilization of the sites for a short term after the data ends (10/2021). This is why training the models  on these extraordinary events is not feasible, which is why we only use the data from after the data hole."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Filter data and convert week of year to integer\n",
    "agg_charging_data = agg_charging_data[agg_charging_data['year'] == 2021]\n",
    "agg_charging_data['week_of_year'] = agg_charging_data['week_of_year'].astype('int32')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Define the model properties:\n",
    "\n",
    "1. Input features: hour_of_day, day_of_week, month_of_year, year\n",
    "    - Why these features: We cannot use real-time or future-dependent inputs unless they are forecasted or modeled beforehand\n",
    "2. Target features: utilizationRate_siteX\n",
    "3. Model parameters: Coefficients (Î¸) for polynomial regression or weights (ð‘Š,ð‘) for neural network.\n",
    "4. Hypothesis function: Polynomial regression: ð‘¦^=â„Žðœƒ(ð‘‹), Neural network: y^=f(W,b).\n",
    "5. Objective funktion: Mean Squared Error (MSE): J(Î¸)=1/m*âˆ‘(y^âˆ’y)^2."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#different data sets to train the models\n",
    "gesamt_charging_data = agg_charging_data[['utilizationRate_total', 'hour_of_day', 'day_of_week', 'year', 'month_of_year']]\n",
    "site1_charging_data = agg_charging_data[['utilizationRate_site1', 'hour_of_day', 'day_of_week', 'year', 'month_of_year']]\n",
    "site2_charging_data = agg_charging_data[['utilizationRate_site2', 'hour_of_day', 'day_of_week', 'year', 'month_of_year']]\n",
    "\n",
    "# Split data\n",
    "X = gesamt_charging_data[['hour_of_day', 'day_of_week', 'month_of_year', 'year']]\n",
    "y = gesamt_charging_data['utilizationRate_total']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False) #shuffle = False ensures to split the data in order\n",
    "X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X, y, test_size=0.1, shuffle=False) #shuffle = False ensures to split the data in order\n",
    "X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(X, y, test_size=0.1, shuffle=False) #shuffle = False ensures to split the data in order"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Neural Network"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# transform/ scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_nn = scaler.fit_transform(X_train_nn)\n",
    "X_test_nn = scaler.transform(X_test_nn)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create model\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_dim=X_train_nn.shape[1]),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)  # FÃ¼r die Vorhersage eines kontinuierlichen Wertes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Modell trainieren\n",
    "epochs = 20\n",
    "history = model.fit(X_train_nn, y_train_nn, epochs=epochs, batch_size=32, validation_split=0.2, shuffle=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#check the overview of the training and validation loss \n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.head()\n",
    "\n",
    "# Plot training and validation loss to see the differences in each epoch\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.plot(history_df['loss'], label='Training Loss')\n",
    "plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation MSE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Vorhersagen\n",
    "y_pred_nn = model.predict(X_test_nn)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Measure performance\n",
    "mse_nn = mean_squared_error(y_test_nn, y_pred_nn)\n",
    "mae_nn = mean_absolute_error(y_test_nn, y_pred_nn)\n",
    "r2_nn = r2_score(y_test_nn, y_pred_nn)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Polynomial regression\n",
    "\n",
    "As a second model we will us a polynominal regression model. In order to find the right hyperparameters, we conduct a grid search on the performance measures to find the right value for the degree (D) and the regularization strenght (alpha)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('polynomial_features', PolynomialFeatures()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge_regression', Ridge())\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'polynomial_features__degree': range(11), \n",
    "    'ridge_regression__alpha': np.logspace(-3, 2, 5)\n",
    "}\n",
    "\n",
    "# Define the scoring metric\n",
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=kf,\n",
    "    scoring=scorer,\n",
    ")\n",
    "\n",
    "# Fit the grid search on the training data\n",
    "grid_search.fit(X_train_poly, y_train_poly)\n",
    "\n",
    "# Get the best hyperparameters and corresponding score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_  \n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Mean Squared Error (Validation Set, Cross-Validation): {best_score}\")\n",
    "\n",
    "# Validate the best model on the separate validation set\n",
    "best_model_poly = grid_search.best_estimator_\n",
    "\n",
    "# Final evaluation on the test set\n",
    "y_pred_poly = best_model_poly.predict(X_test_poly)\n",
    "\n",
    "mse_poly = mean_squared_error(y_test_poly, y_pred_poly)\n",
    "mae_poly = mean_absolute_error(y_test_poly, y_pred_poly)\n",
    "r2_poly = r2_score(y_test_poly, y_pred_poly)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot Predictions\n",
    "# Index erstellen, um die Testdaten in der Reihenfolge darzustellen\n",
    "indices = np.arange(len(y_test_poly))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# plot actual values\n",
    "plt.plot(indices, y_test, label='Actual Values', color='blue', linestyle='-', alpha=0.7)\n",
    "\n",
    "# replace negative values with 0\n",
    "y_pred_nn = np.maximum(0, y_pred_nn)\n",
    "y_pred_poly = np.maximum(0, y_pred_poly)\n",
    "\n",
    "# plot predicted values\n",
    "plt.plot(indices, y_pred_poly, label='Predicted Values Polynominal regression', color='orange', linestyle='-', alpha=0.7)\n",
    "plt.plot(indices, y_pred_nn, label='Predicted Values Neural Network', color='red', linestyle='-', alpha=0.7)\n",
    "\n",
    "plt.title(\"Actual vs. Predicted Values (Test Set)\", fontsize=14)\n",
    "plt.xlabel(\"Index\", fontsize=12)\n",
    "plt.ylabel(\"Utilization Rate\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"Neural Network - MSE: {mse_nn}, MAE: {mae_nn}, RÂ²: {r2_nn}\")\n",
    "print(f\"Polynomial Regression - MSE: {mse_poly}, MAE: {mae_poly}, RÂ²: {r2_poly}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The comparison indicates a better performance of the polynominal regression model, likely because of the limited complexity. Lets use the model to predict the next weeks utilization."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Future prediction\n",
    "We use the regression model (better performing) to predict utilizations in the future. Based on our goal to predict relatively short time periods, we choose to predict the next week after the dataset ends."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert X_test back to a DataFrame if it's a NumPy array\n",
    "if not isinstance(X_test, pd.DataFrame):\n",
    "    X_test = pd.DataFrame(X_test, columns=['hour_of_day', 'day_of_week', 'month_of_year', 'year'])\n",
    "\n",
    "# Extend the test set one month forward\n",
    "def extend_test_set(X_test, n_steps=24):\n",
    "    extended_test_set = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "    last_row = X_test.iloc[-1].copy()  # Start from the last row\n",
    "    extended_rows = []\n",
    "    for _ in range(n_steps):  # Simulate the next 'n_steps' rows\n",
    "        last_row['hour_of_day'] += 1\n",
    "        if last_row['hour_of_day'] > 24:  # Reset hour_of_day and increment day_of_week\n",
    "            last_row['hour_of_day'] = 1\n",
    "            last_row['day_of_week'] += 1\n",
    "        if last_row['day_of_week'] > 7:  # Reset day_of_week and increment month_of_year\n",
    "            last_row['day_of_week'] = 1\n",
    "            last_row['month_of_year'] += 1\n",
    "        if last_row['month_of_year'] > 12:  # Reset month_of_year and increment year\n",
    "            last_row['month_of_year'] = 1\n",
    "            last_row['year'] += 1\n",
    "        extended_rows.append(last_row.copy())  # Add the new row\n",
    "    \n",
    "    extended_test_set = pd.concat([extended_test_set, pd.DataFrame(extended_rows)], ignore_index=True)\n",
    "    return extended_test_set\n",
    "\n",
    "# Generate extended test set\n",
    "X_test_extended = extend_test_set(X_test, n_steps=300)\n",
    "\n",
    "# Predict on the extended test set\n",
    "y_extended_pred = best_model_poly.predict(X_test_extended)\n",
    "y_extended_pred = np.maximum(0, y_extended_pred)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(y_test)), y_test, label='Test Set', color='blue')\n",
    "plt.plot(range(len(y_test), len(y_test) + len(y_extended_pred)), y_extended_pred, label='Next Weeks Predictions', color='orange')\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Utilization Rate\")\n",
    "plt.title(\"Test Set and Extended Predictions\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "While the prediction is not perfect, it shows the characteristics of the data. The plot clearly illustrates the daily peaks and the overall rising trend."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Time Series: ARIMA\n",
    "\n",
    "The models performance are satisfying and show the basic structure and trend of the data, but the predictive performance is still not optimal. Because we rely on time-dependent data, we also tested the use of an ARIMA model, which focuses on time series."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load and Prepare the Data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Select 'utilizationRate_total' column from the DataFrame\n",
    "data = agg_charging_data[['utilizationRate_total']]  # This keeps it as a DataFrame, not a Series\n",
    "\n",
    "data.index = pd.to_datetime(data.index)\n",
    "\n",
    "data.index.freq = 'H'\n",
    "\n",
    "data['utilizationRate_total'].replace(0, np.nan, inplace=True)\n",
    "data['utilizationRate_total'].fillna(method='bfill', inplace=True)\n",
    "data['utilizationRate_total'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "data.index = pd.to_datetime(data.index).tz_localize(None)\n",
    "\n",
    "print(data.head())\n",
    "print(data['utilizationRate_total'].isna().sum())\n",
    "print(data.shape)\n",
    "# Plot the DataFrame\n",
    "plt.plot(data)\n",
    "plt.title('Utilization Rate Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Utilization Rate')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Check stationarity\n",
    "We use statistic tests like the Dicky Fuller test to determine if the series is stationary. We copied the code out of the  This is necessary to be able for the model to be processed"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def test_stationarity(timeseries):\n",
    "    \n",
    "    #Determing rolling statistics\n",
    "    rolmean = timeseries.rolling(window=168).mean()\n",
    "    rolstd = timeseries.rolling(window=168).std()\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print('Results of Dickey-Fuller Test:\\n')\n",
    "    dftest = adfuller(timeseries)\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data Transformation and Decomposition\n",
    "We transform the data by calculating its log and decompose it. Since the data shows a daily trend (peaks) and a weekly one (lower peaks on weekends), we use MSTL to decompose 2 seasonal periods."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ts_log = np.log(data['utilizationRate_total'])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "res = MSTL(ts_log, periods=(24, 24*7)).fit()\n",
    "# Komponenten aus dem res-Objekt extrahieren\n",
    "observed = res.observed\n",
    "trend = res.trend\n",
    "seasonal = res.seasonal\n",
    "residuals = res.resid\n",
    "print(seasonal.info())\n",
    "\n",
    "# Anzahl der Subplots berechnen\n",
    "num_seasonal = len(seasonal.columns)\n",
    "num_subplots = 3 + num_seasonal  # Observed, Trend, Residuals + jede saisonale Komponente\n",
    "\n",
    "# Subplots erstellen\n",
    "fig, ax = plt.subplots(num_subplots, 1, figsize=(12, 3 * num_subplots), sharex=True)\n",
    "\n",
    "# Plot for the observations\n",
    "ax[0].plot(observed, label='Observed', color='black')\n",
    "ax[0].set_title('Observed')\n",
    "ax[0].legend()\n",
    "\n",
    "# Plot for the trends\n",
    "ax[1].plot(trend, label='Trend', color='blue')\n",
    "ax[1].set_title('Trend')\n",
    "ax[1].legend()\n",
    "\n",
    "# Plots for every season\n",
    "for i, col in enumerate(seasonal.columns):\n",
    "    ax[i + 2].plot(seasonal[col], label=f'Seasonal {col}', color='green')\n",
    "    ax[i + 2].set_title(f'Seasonal Component: {col}')\n",
    "    ax[i + 2].legend()\n",
    "\n",
    "# Plot for residuals\n",
    "ax[-1].scatter(residuals.index, residuals, label='Residuals', color='red', alpha=0.6)\n",
    "ax[-1].axhline(0, linestyle='--', color='gray')\n",
    "ax[-1].set_title('Residuals')\n",
    "ax[-1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ts_log_decompose = residuals.copy()\n",
    "ts_log_decompose.interpolate(method='time', inplace=True)\n",
    "test_stationarity(ts_log_decompose)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Test Statistic is lower then the critical values and the p-value is very small, indicating a stationary time series."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Determine options\n",
    "Using ACF and PACF charts to determine the p and q value"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#ACF and PACF plots:\n",
    "lag_acf = acf(ts_log_decompose, nlags=20)\n",
    "lag_pacf = pacf(ts_log_decompose, nlags=20, method='ols')\n",
    "\n",
    "#Plot ACF: \n",
    "plt.subplot(121) \n",
    "plt.plot(lag_acf)\n",
    "plt.axhline(y=0,linestyle='--',color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(ts_log_decompose)),linestyle='--',color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(ts_log_decompose)),linestyle='--',color='gray')\n",
    "plt.title('Autocorrelation Function')\n",
    "\n",
    "#Plot PACF:\n",
    "plt.subplot(122)\n",
    "plt.plot(lag_pacf)\n",
    "plt.axhline(y=0,linestyle='--',color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(ts_log_decompose)),linestyle='--',color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(ts_log_decompose)),linestyle='--',color='gray')\n",
    "plt.title('Partial Autocorrelation Function')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Define confidence interval\n",
    "conf_interval = 1.96 / np.sqrt(len(ts_log_decompose))\n",
    "\n",
    "# Determine p (where PACF cuts off sharply)\n",
    "p = next((i for i, x in enumerate(lag_pacf) if abs(x) < conf_interval and i > 0), None)\n",
    "\n",
    "# Determine d (use default value of 1)\n",
    "d = 1\n",
    "\n",
    "# Determine q (where ACF cuts off sharply)\n",
    "q = next((i for i, x in enumerate(lag_acf) if abs(x) < conf_interval and i > 0), None)\n",
    "\n",
    "print(f\"Suggested value for p (AR): {p}\")\n",
    "print(f\"Suggested value for q (MA): {q}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fitting Arima model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "split_ratio = 0.9\n",
    "train_size = int(len(ts_log_decompose) * split_ratio)\n",
    "residual_train, residual_test = train_test_split(ts_log_decompose, train_size=train_size, shuffle=False)\n",
    "\n",
    "model = ARIMA(residual_train, order=(p, d, q))  \n",
    "results_ARIMA = model.fit() \n",
    "plt.plot(residual_train)\n",
    "plt.plot(results_ARIMA.fittedvalues, color='red')\n",
    "plt.title('RSS: %.4f'% sum((results_ARIMA.fittedvalues-residual_train)**2))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Forecasting on test set"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ensure frequency and alignment for all components\n",
    "full_index = pd.date_range(start=residuals.index.min(), end=residuals.index.max(), freq='H')\n",
    "residuals = residuals.reindex(full_index)\n",
    "trend = trend.reindex(full_index)\n",
    "seasonal = seasonal.reindex(full_index)\n",
    "\n",
    "# Fill missing values and ensure no NaNs\n",
    "residuals.interpolate(method='time', inplace=True)\n",
    "trend.interpolate(method='time', inplace=True)\n",
    "seasonal.interpolate(method='time', inplace=True)\n",
    "\n",
    "# Set consistent frequency\n",
    "residuals.index.freq = 'H'\n",
    "trend.index.freq = 'H'\n",
    "seasonal.index.freq = 'H'\n",
    "\n",
    "# Train-test split using slicing\n",
    "train_size = int(len(residuals) * split_ratio)\n",
    "residual_train = residuals.iloc[:train_size]\n",
    "residual_test = residuals.iloc[train_size:]\n",
    "trend_train = trend.iloc[:train_size]\n",
    "trend_test = trend.iloc[train_size:]\n",
    "seasonal_train_1 = seasonal.iloc[:train_size, 0]\n",
    "seasonal_test_1 = seasonal.iloc[train_size:, 0]\n",
    "seasonal_train_2 = seasonal.iloc[:train_size, 1]\n",
    "seasonal_test_2 = seasonal.iloc[train_size:, 1]\n",
    "\n",
    "# Predict residuals using ARIMA\n",
    "residual_predictions = results_ARIMA.predict(start=len(residual_train), end=len(residuals) - 1)\n",
    "residual_predictions.index = residual_test.index\n",
    "\n",
    "# Align indices for all components\n",
    "trend_test.index = residual_test.index\n",
    "seasonal_test_1.index = residual_test.index\n",
    "seasonal_test_2.index = residual_test.index\n",
    "\n",
    "# Ensure predictions match in length\n",
    "assert len(residual_predictions) == len(trend_test), \"Residual predictions length mismatch!\"\n",
    "\n",
    "# Reconstruct predictions (in log scale)\n",
    "log_predictions = (\n",
    "    residual_predictions\n",
    "    + trend_test\n",
    "    + seasonal_test_1\n",
    "    + seasonal_test_2\n",
    ")\n",
    "\n",
    "# Apply inverse log transformation to return to original scale\n",
    "full_predictions = np.exp(log_predictions)\n",
    "\n",
    "# Trim full_predictions to match test data length\n",
    "full_predictions = full_predictions.iloc[:len(data.iloc[train_size:])]\n",
    "\n",
    "# Ensure the test set length matches full_predictions\n",
    "test = data.iloc[train_size:]['utilizationRate_total']\n",
    "assert len(test) == len(full_predictions), \"Final lengths still do not match!\"\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test, label=\"Original Test Data\", color='blue')\n",
    "plt.plot(full_predictions, label=\"Predictions (Test Set)\", color='green')\n",
    "plt.legend()\n",
    "plt.title('ARIMA Model Predictions Test Set')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "mse_arima = mean_squared_error(test, full_predictions)\n",
    "mae_arima = mean_absolute_error(test, full_predictions)\n",
    "r2_arima = r2_score(test, full_predictions)\n",
    "\n",
    "print(f\"ARIMA model - MSE: {mse_arima}, MAE: {mae_arima}, RÂ²: {r2_arima}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we see, the ARIMA model handles the time series data much better then the other models."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DynamoData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
